{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhQ8g-UDLpqn",
    "outputId": "bade8d97-4527-480e-de42-1cf3d7ba770a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y-MU2H5KbIZ"
   },
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBvM4FolKbIZ"
   },
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqHVSXvVKbIa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "import bottleneck as bn\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jSKlwM2KbIa"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FfmcWszKbIa"
   },
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXxRDM7NKbIa"
   },
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6aQkgc3KbIa",
    "outputId": "62cd78b9-c8bb-4c4a-eab2-921577957657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = '/content/drive/My Drive/Study/Project3/ml-20m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qBQWbvSKbIa"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq7xOWy9KbIa"
   },
   "outputs": [],
   "source": [
    "# binarize the data (only keep ratings >= 4)\n",
    "raw_data = raw_data[raw_data['rating'] > 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "C_YwUsZwKbIa",
    "outputId": "f3f23937-d5e1-48a2-8e81-425353baf851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "6        1      151     4.0  1094785734\n",
       "7        1      223     4.0  1112485573\n",
       "8        1      253     4.0  1112484940\n",
       "9        1      260     4.0  1112484826\n",
       "10       1      293     4.0  1112484703"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75JhuEB_KbIb"
   },
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdOzp4RfKbIb"
   },
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChLy_ymAKbIb"
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlcITsDZKbIb"
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RYQPeH2KbIb"
   },
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQGWw184KbIb"
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9-rt2ezKbIb",
    "outputId": "e4d2c9e3-ad4a-480b-dccc-6e60fbad85e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbyWcf1pKbIb"
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTku1H1DKbIb"
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdASvG79KbIb"
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne0HiGtOKbIb"
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Av46YOzKbIc"
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8MYrWjdKbIc"
   },
   "outputs": [],
   "source": [
    "# pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fW7cBfvNKbIc"
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLuS5LXwKbIc"
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pCxg4OUKbIc",
    "outputId": "b750fd4a-e8cc-4486-fc00-7668e12ba344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSpz_DX0KbIc"
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0q_LYlJFKbIc",
    "outputId": "d59a3f80-9db4-4919-ea30-f9a3b1bb36c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D12r0whSKbIc"
   },
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F_kXEokKbIc"
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUHPsKhZKbIc"
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRNSTf0QKbIc"
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4o0GVKaKbIc"
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KBW_3aqKbIc"
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdB3PRQJKbIc"
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McZLq8QkKbIc"
   },
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIlMAfz4KbId"
   },
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCPIIYYMKbId"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEcLKHvcKbId"
   },
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvW4hHdrKbId"
   },
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dIsvORCKbId"
   },
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy2LESs4KbId"
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P1xXakVKbId"
   },
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94iVFyI_KbId"
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxhsnuTDKbId"
   },
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHeuM78SKbId"
   },
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzi4hI4uKbId"
   },
   "outputs": [],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nrgFBSQKbId"
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVN2K0N5KbId"
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1zbIgdXKbId"
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWW9jkv8KbId"
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ2uu1M_KbId"
   },
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epbUOpjQKbId"
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = list(range(N_vad))\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe8WpfC4KbId"
   },
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xpg3DDfBKbId"
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvMW1xduKbId"
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KklHu46iKbId"
   },
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIxPZcRwKbId"
   },
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txnn1fc1KbId"
   },
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zguWFBo8KbIe"
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJkeTnt4KbIe",
    "outputId": "6af2a879-f07c-4791-880d-6e9ad101df36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-29-238c8eded668>:40: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5U-tOm1KbIe"
   },
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYqzMPB0KbIe"
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_6LvF7JKbIe",
    "outputId": "398d748c-606f-4825-e51a-4e0746b13384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: /content/drive/My Drive/Study/Project3/ml-20m/log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = '/content/drive/My Drive/Study/Project3/ml-20m/log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtRExyrSKbIe",
    "outputId": "4040023a-5819-4657-ddaf-85d3ba960455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /content/drive/My Drive/Study/Project3/ml-20m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-20m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSJJOgKJKbIf"
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGnvfwA-KbIf"
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "3YxiD4pwKbIf",
    "outputId": "33fc2858-92dd-43e3-bf6a-85828d4bd824"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMdqcRMWKbIf"
   },
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wOALoUOKbIf"
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bJdNtXpKbIf"
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Z14AeVaKbIf",
    "outputId": "fc4fe2ca-1fa2-454c-8c3f-d2bba0a4ccd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IfeVohUKbIf"
   },
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axVRJgY-KbIf",
    "outputId": "e41ad683-a71b-4045-af22-51f0cd3bee8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /content/drive/My Drive/Study/Project3/ml-20m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-20m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xR3wWxPvKbIg",
    "outputId": "200c5807-e524-4e48-a1d5-aa97052c088f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Study/Project3/ml-20m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "    \n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQW1bzwkKbIg",
    "outputId": "86e867ca-364c-43cd-f532-f0772c04aa52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.42472 (0.00211)\n",
      "Test Recall@20=0.39443 (0.00270)\n",
      "Test Recall@50=0.53571 (0.00284)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEkCQugNKbIg"
   },
   "source": [
    "### Train a Multi-DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOnTW8teKbIg"
   },
   "source": [
    "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "_PwcgFZ6KbIg",
    "outputId": "07a516cc-62eb-4494-ce42-e78e7b094861"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2658139b33d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_items' is not defined"
     ]
    }
   ],
   "source": [
    "p_dims = [200, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "UzQ33K6QKbIg",
    "outputId": "b72053c0-a3fc-479c-dc7b-b8ad97cbe06b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3225163a736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiDAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m98765\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YkGwe6sKbIg"
   },
   "source": [
    "Set up logging and checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgD1SObKKbIg"
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeTVNSjiKbIg"
   },
   "outputs": [],
   "source": [
    "log_dir = '/content/drive/My Drive/hegoiy/log/DAE/{}'.format(arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dwanb3xaKbIh"
   },
   "outputs": [],
   "source": [
    "chkpt_dir = '/content/drive/My Drive/hegoiy/checkpoints/DAE/{}'.format(arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ_zOlxlKbIh"
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veNCK_HXKbIh"
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            feed_dict = {dae.input_ph: X, \n",
    "                         dae.keep_prob_ph: 0.5}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "                    \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jckmp0taKbIh"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzzHzNc2KbIi"
   },
   "source": [
    "### Compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K53KyHCgKbIi"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
    "saver, logits_var, _, _, _ = dae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYBO2gmxKbIi"
   },
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEAJe5t5KbIi",
    "outputId": "f5bc8ea7-31cb-4262-df87-c01f27728f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /content/drive/My Drive/hegoiy/checkpoints/DAE/I-200-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/content/drive/My Drive/hegoiy/checkpoints/DAE/{}'.format(arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXTvYM_GKbIi",
    "outputId": "1b577af3-b08e-433f-a316-668ceb73f89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/hegoiy/checkpoints/DAE/I-200-I/model\n"
     ]
    }
   ],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbCzt-JKbIi",
    "outputId": "ecae6122-8ba2-4936-c5b9-2b19a6e066a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.43525 (0.00210)\n",
      "Test Recall@20=0.39381 (0.00260)\n",
      "Test Recall@50=0.52518 (0.00275)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jEkCQugNKbIg",
    "wzzHzNc2KbIi"
   ],
   "name": "vae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
