{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "vae_25m_10percentuser_150epochs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jEkCQugNKbIg",
        "wzzHzNc2KbIi"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhQ8g-UDLpqn",
        "outputId": "891a9172-5caf-4413-82ff-eacd3398b094"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y-MU2H5KbIZ"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBvM4FolKbIZ"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqHVSXvVKbIa"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "import bottleneck as bn\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jSKlwM2KbIa"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FfmcWszKbIa"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXxRDM7NKbIa"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-25m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6aQkgc3KbIa",
        "outputId": "4230347d-9b28-4064-9299-9dcff9797bdf"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "### change `DATA_DIR` to the location where movielens-25m dataset sits\n",
        "DATA_DIR = '/content/drive/My Drive/Study/Project3/ml-25m'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBQWbvSKbIa"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7xOWy9KbIa"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "C_YwUsZwKbIa",
        "outputId": "13bc48f4-ecc3-413d-8652-2b9d60b5f926"
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147880044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147868828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>665</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147878820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1088</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1147868495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1237</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147868839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      296     5.0  1147880044\n",
              "2       1      307     5.0  1147868828\n",
              "3       1      665     5.0  1147878820\n",
              "5       1     1088     4.0  1147868495\n",
              "8       1     1237     5.0  1147868839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75JhuEB_KbIb"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdOzp4RfKbIb"
      },
      "source": [
        "- Select 10% users as heldout users, 10% users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChLy_ymAKbIb"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlcITsDZKbIb"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RYQPeH2KbIb"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQGWw184KbIb"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9-rt2ezKbIb",
        "outputId": "afe7a50c-cd1e-44c2-af24-f25685f3be7b"
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 12448242 watching events from 160776 users and 40857 movies (sparsity: 0.190%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbyWcf1pKbIb"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTku1H1DKbIb"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = int(n_users/10)\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdASvG79KbIb"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0HiGtOKbIb"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Av46YOzKbIc"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8MYrWjdKbIc"
      },
      "source": [
        "# pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW7cBfvNKbIc"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLuS5LXwKbIc"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pCxg4OUKbIc",
        "outputId": "ce8687b4-cb83-44f9-f3ae-56eea0e9297f"
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n",
            "10000 users sampled\n",
            "11000 users sampled\n",
            "12000 users sampled\n",
            "13000 users sampled\n",
            "14000 users sampled\n",
            "15000 users sampled\n",
            "16000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpz_DX0KbIc"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q_LYlJFKbIc",
        "outputId": "bc22273c-a4e1-46dd-c213-98f91b0d1498"
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n",
            "10000 users sampled\n",
            "11000 users sampled\n",
            "12000 users sampled\n",
            "13000 users sampled\n",
            "14000 users sampled\n",
            "15000 users sampled\n",
            "16000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D12r0whSKbIc"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F_kXEokKbIc"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
        "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUHPsKhZKbIc"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRNSTf0QKbIc"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4o0GVKaKbIc"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KBW_3aqKbIc"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdB3PRQJKbIc"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZLq8QkKbIc"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIlMAfz4KbId"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCPIIYYMKbId"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEcLKHvcKbId"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvW4hHdrKbId"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dIsvORCKbId"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2LESs4KbId"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P1xXakVKbId"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iVFyI_KbId"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxhsnuTDKbId"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHeuM78SKbId"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzi4hI4uKbId"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nrgFBSQKbId"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVN2K0N5KbId"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1zbIgdXKbId"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWW9jkv8KbId"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2uu1M_KbId"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epbUOpjQKbId"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "# training batch size\n",
        "batch_size = 500\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = list(range(N_vad))\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe8WpfC4KbId"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpg3DDfBKbId"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvMW1xduKbId"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklHu46iKbId"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIxPZcRwKbId"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txnn1fc1KbId"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zguWFBo8KbIe"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJkeTnt4KbIe",
        "outputId": "8e767d32-0b47-4605-de80-23e313154496"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-29-238c8eded668>:40: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5U-tOm1KbIe"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYqzMPB0KbIe"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_6LvF7JKbIe",
        "outputId": "930e28e3-a320-4cc7-b4f4-284368091017"
      },
      "source": [
        "log_dir = '/content/drive/My Drive/Study/Project3/ml-25m/log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/drive/My Drive/Study/Project3/ml-25m/log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtRExyrSKbIe",
        "outputId": "2ee51c8a-e699-44dc-fbf4-729d9032e089"
      },
      "source": [
        "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-25m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/drive/My Drive/Study/Project3/ml-25m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSJJOgKJKbIf"
      },
      "source": [
        "n_epochs = 150"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGnvfwA-KbIf"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YxiD4pwKbIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "bc5be864-af04-4361-829e-153c89a7f1d0"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt4AAADVCAYAAABgzPe1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxTdbo/8M/JvjVNl7RNaaG0bGVVQUFAHNl1WJQroxe36ygO15UZ9TUM92pRHBjGe7mDiqLcGecyjsso/MSL4sAgXAWUQWUEhCK0lpbuS/Y0+/n9kTZaaZtAk5Ymn/fr1RftOWnOk4ek58k3z/l+BVEURRARERERUVxJ+joAIiIiIqJkwMKbiIiIiKgXsPAmIiIiIuoFLLyJiIiIiHoBC28iIiIiol7AwpuIiIiIqBfI+jqA3mQ2OxEM9v7siRkZOjQ3O3r9uImEOYwN5jE2mMeeYw5jg3mMDeax55jD70gkAtLStJ3uS6rCOxgU+6Twbj829QxzGBvMY2wwjz3HHMYG8xgbzGPPMYeRsdWEiIiIiKgXsPAmIiIiIuoFLLyJiIiIiHoBC28iIiIiCgsEg3B7/X0dRkJKqosriYiIqP8QRRGiGJolore0evzwB4LQquWQCBd2XLvLi+PftsDl9mP8cCMMOmXM4hJFEY5WHxotbjRZW+HzB9u2AyJEaFVyGHRKGHQKpOoUkEo6H1v1+YP4psoCm8uLDL0KmakqGHRKtHr9OFbejKNnmnGsvBmtngBGF6bj6lE5uGxoJpRyKYJBEdVNTpw5Z0FNkwtSqQCFXAqlXIJ0gwYejw9KmRQKuQRymQReXxAeXwAeXwBeXxBqpRQpGgX0GgW0ahnsLh8aLa1oMLeiydoKlVIGU7oGORkamNK1UCqk8PmD8PpDvy+VCNCoZNCqZJDLpBBFEfZWHyx2DywOL+wuL9ze0PHcXj9y0jWYPNoUs/+DWGDhTURE1AWvL4CaZifONTjRYnNDkAiQSQRIpRKoFFLkGXXIz9JCLpNGdX8+fxBl1VacOGtGeY0Vg016zBif16FACwZFfPlNI/72eRVUShmmjcvF2KIMyKQdC6mgKKLR3IqTZ81oMLvQYGmFTCLBpFHZMGV0PpVZV0RRRJPVjboWFzzeQLjY8QdEKOQSaJQyqJUyKOVSNFndqG5yoLrRidpmFwQBUClkUCulUCtlMOiUMKaqYDSokWlQQ62QIojvimi/Pwh3W2Hk8QagVspQlJsKpeK7HHq8AXz6dR32fHEOjZZWTBuXi7kTByJdrzovB1aHFwadAkI3RbIoinC6/WiytsJs88CUqUV2mrrD7zRZWvHh3yvxydFa+PxBSAQBKRo59FoF0lOUMKapkZ2mgdGghlYlg9cfhM8fhM8fQE2TE0fLm1FebUP7vB6v/+0bjB6cgSljcjBqcDosDi8aLa1oNLfC5fFjYJYOhQNSkapVdBqz2e7B6XMWnK6y4kyNFQ1mF1o9gaj+PwUAWWlqDMpJCX1lp8Dq9OLI6SYcL2+G29vxfqQSAaIYyqdOLcdlQzKh08jx95MNOFr2NVQKKQZlp6CywYFWT2gkXKWQQhRDr5GezmUiCEB6igoujz98/5GEXg8i/IHOjy4IQPGgtEuu8BZEUUyauV+amx19MtWN0ZiCxkZ7rx83kTCHscE8xkYi5LG9ELE4PLA6vZAIAlSKUOGkVkiRolVEHO1ze/348ptGfPp1PRwuH4YPNKB4UBqG5RugVnY/rvPDHNpcXmhVsvNG6Ty+AM7W2VHV4EBQFMNFr1wqQVaaGnlZOijlkYveuhYXyqqtONfowLkGB6oanRAEYEhuKooGpGJoXip0anlof6Mz/G+D2YVIZ0mJICA3U4uC9iInJwX5bXG1evwor7HhTLUVp89ZcOacFV5/EIIA5GZqUdPohEQiYNLIbMyckI/Kejt2HqpEXYsLWQY1vP4ALA4vUnUKTB1jgtGgRmW9HZUNDlQ1OOD5XgElkwoIBkPFU9EAPaaOMWHU4HS4vQHYXT44Wn1wtvrg9QXg8Qfh9QXgbPXhXJMT5xoc5xVjkR5zdroapgwtJBIB7raCyeXxw2z3XNB9AaHCr8CUguH5afAHgth/tDZUnGbrYMrQ4vPSBgDAlDE5mDQyB5UNDpyqNOObKgucbj+0KhkKTHoMNumRZ9TC7vKhydoaGh22tKLR6j6voMtMVWH04HQMyzfgm2obPj5SDUEArh6Vg/xsHWzO0AiqzelDk9WNBosLXl+w0/gFAAUmPcYWZWBsUQZUCikOHq/DweN1MNs93T72zFQV8rN0CARFeLwBuL0BOFq9aLaFfk8hl6AoNxW5GVoYDd+9oVHKJYAghHuGnW4/zA4PLHYPzHYPapqcqKizo9nmDh8rVavAuCGZuHxoJowGNVpsbjRZ3Wi2uSERBIwtysBgkz78CUNQFPFNpQWffl2HqgYHCnJSMCQvFUPyDDCmqiAIAkQxVPzqU9WoqbPB6wuE35QoZBIoFFKo5FLIZRK0evywu3ywu7ywu3zQaeTIMqiRkaqCTCqBKIqwuXyoa3aitsUFny8IuVwSuh+ZFIGgCJfbB5fHD5fbDwhAmk4ZGulPUSJFI4dKIYNKIYVCJun2zVg8SSQCMjJ0ne5j4d0LEuEk3deYw9hgHi9eq8ePJqsbZrsHQwrSoRTELj/K/T6X24cWuwc2pzf05fLB5w9AEAQIAiBAgEIugV6jgF6rQKpWgbQUJRRRFJPBoIiqBgfO1tvhbPXB6fbD5fbB5w9icK4exYPSkJOugSAICAZFnKm24stvGnG0rBlNVjf8gc6LCABto5B6DBmQiqK8VKSo5XC5Q4WV0+1D6VkzvvymCR5fAJmpKmToVSirscEfCIYL0VSdou1xyZGdpsGkUdlQKUIFeftz0Wz34LVdp3DkdBMkgoCMVCWMBjX0GgWqm5yobnQi2M1pShCAnHQNBmanIDdDg5wMLUzpGmSlqVHd5MSX3zTiy28aUdvsAgDIZRLkZmqRb9TBHwyNPjda3B3vE4AxTY08ow55Rm3o3ywdjAYVRBEIBET4g0E43X5U1dtxtt6Oijo7ztbZYXf5wnGlp6jQYnNDbPt5QKYOIwYZMHJQqNjTqGRoMLuw+/A5fHKsJlzUDczW4YZJgzBheBZEiDha1oyP/1GDo+XNEEVAqZBiYJYOA7NSMHxwOjTy0JuQ9BQV7C4vPv26HvuP1aKmydnt80ciCFArpRiQqUVeVugx5mZooVbKoJCFWgVkUgk8vgBa2wprtzeAdL0KOekayGWdP//b39Q1WlrRaGmF1xd6oyEJPeEhb/u0QKmQQimXwur04lSlBaeqzKioDf19Gj/ciBnj8zBkQCoEQUCTtRUfHqrEx1/Vhp+3WWlqjBhowIBMHWqanSivsXV4vshlEmS2j7yH/1XDoFPgbL0dx8tbcLLSDI83AJVCimnjcjH7yvzzRtW//7hsTi/qza1wewOhHMlDbwINKUroNeePXAeDIk5WmnG2zo50fei5bTSooZJLUVnvQFmNFWXVVlQ3OSGXScJFo0Ypw6CcFAzLNyA/S3fepx0XwtHqw9l6O9QKGQpMKRfcPhMtnl++w8K7DQvv/os5jI3+nkebywu/P4i0FGWPRzICwSBKz1pwptoKhVzSNtIrg1wmgdnuQZO1FU2W0GhQk7UVTnfH0TK5TII8oxb5WTpoVPJwYSEIoY+I61taUW92hQuxCyERBAwwalGYq0ehSY/sdA18/mBb76K/7SPo0Ajq9z96bu9/FAQBNqcXAJCWokRBTgrKamywOb2QSQUUD0pHnlGL1PZ+UK0CQTE0gu32hoqsc42hPs7qRmenHyNrlDJcWZyFq0flYGheqDjy+gLhNoqqBkd4ZMvm9MLrD0KrkmHmhHzMGJ+HQXlpeHt3Kd7ZV4ZAUMTsK/MhCECjxY1GSyssDg9MGVoMNoVyMCgnBXKZBIFAEP6ACK8/gLpmF87Wh0bDK+vt4RHCH+Zy+EADrhhmxMiCNGSnac7rF7Y6PDhTbYXL40eeMVR8fr/tIVqiKMJs9+BsfagIr2txITdDi6K8VBSa9N1+CuB0+/D3E/UwGtQYNTi90+e3xeGBxxeA0aAOF09dvaZFUcS3taE3BTq1HDq1HClqObRqOZRyCRRyaY+KuXjxeAPwB4PQquSd7rc6PCirsaEgJ6XTAtnjDaDe7Aq/iY30d8IfCKKy3oGRQ41wO7sfmabu9ffzSyyx8G7Dwrv/Yg5jI9o8+vwBlNfYYHZ4kJOuQU66JjxS+X3BYKjQaB/ZcrT6MDAnBUN+0K8JhC46OtfoRLPVDbM9NHJstnsgIlQwSqUSyKQCBmWn4IphRhgN6vDvnmtw4MO/V+LQiXoEgiJSdQoUmvQozA0VM7XNLtS1uFDX7ITL44dKIQv3pKZo5DAa1MhOUyMrTQMRIr441YgvTjXC0dp1Udw+WpaZqm77V4WMtouQvCLw9ZlGVNY7cK4x9HF/UAwVO0FRhF6rQE6aBtnpGmSnq5GhV4VHtPVaBZRySeiCqLaeSo8vEB4Rtzq9qDe78G2NDeW19i77HU0ZGgzPN2BovgFFuXqkapVQyCXhj34bLK04WWHGibNmVNTaUGDSY/wwI8YWZURsA/k+l9uP8lorPN4gNKpQXrUqGQwpygsq3MqqrXj/07P4x5kmKOVSmDK1qKi1YWRBGu6cMxxZaZqo76srHm8g9DxocaG+xYV0vQqXDc2ETt15EZcI+LcxNpjHnmMOv8PCuw0L7/6LOezI0erDJ1/VIE2vxJjCjC5Hh37IaExBVbUZR0434e8n6mF1hq5qT9erkKFXwu0NoLTSjDPVtvPaENL1SqTplPD4gh1GRgOdvKakEiHc79psdaOywXFen2OKJnQFvkQiIBAQEQiGek7bRy3zs3S4bEgmKursOFbeDIVcgmvG5iI7TY3yWhvKa2xoMLcCAJRyadtV8Bro1HK0ev1o9YTiszm9aLB8NwNA++0vG5qJCcOzMLowHaIohm/v8wfbPjaWdzla1lvPx6Aoor7FhWarGwq5NPzxvE4tj/r//FJzrsGBDw6dRVWDE9dPzMfVo3L6rA8zEfBvY2wwjz3HHH6HhXcbFt79V3/PoccXQLPV3TbFUaBthFREhl6FrDR11COQQVHE/qO1eGdfWXi0ViIIGJKXirFFGQgGxbbRXyfqWlyhC9DSNaHRXoMaTXYvDh2vhdcfRIZeiZx0DVrsHjTb3KE+TAD52TqMGJiGEYPSkJmqQn2LC7XNoS+r0wNlWwGoUsigUcnCvZNGgxoalQzlNTZ8U2XBqUoLKhvsMBrUGJilQ35W6IIzo0GFtBRll7NANFhacaStL/fMOStSNHLMGJ+H667IO2/k0tEa6meONKNB+8wHDWYXPL4gRgw0RNVD3ZX+/ny8FDCHscE8xgbz2HPM4XdYeLdh4d1/Xeo5DAZF2F2hNgGr0wtr27RR1U2h2REaza3dTrekU8uRrldC+r3eU4lEQJZBjdxMLUwZWijlUmz7uBzf1towNC8VS2YOgz8QxFdlTfjqTDOqGhwAQj29poxQe4jXH0SDOdRrbHV4odcqMH6YERNHZmNIXmq4T7T9YiiJAGguoZFUp9sHhUza5UVcfeVSfz72B8xhbDCPscE89hxz+J3uCm/O4039nj8QRFWDA6laBQwpygu+YjsQDLZdBOaDw+WFw+2Hw+WFv+1NmgCELhzzB+By+8NX99tbfbA5vLC0TTn1w7ewggBkp2mQn6XD1aNykN02st3eLgAATW0XkjVYWkP9zt+7D38giFNVFnz6dX14W6pWgaXzRmLSqOzwCG/RgFQsmlYEq9MLhUzS5ei5xxuAKUePlpbzZzoQBOGS7IPtr+0UREREnYm68Ha5XKioqIDT6YRWq0VBQQE0mp5fDEPkaPXB6vC0zUt6/sf//kCo97ez7QeP12HHwQo0WUPTgcmkAjLaLoYzaBXQ6xRI1SigbZsKLTQa7fneyLQHdpcv6sn/BQHhi/a0anloxgiTHqna0EphqVoFUrVK6HUKpOkUERfVKMjRRzxmq8ePurY+31GD07ssrLtahKGdUiGF9BKcxYCIiChZRCy8bTYbVq1ahV27dkEulyMlJQUOhwM+nw+zZ89GSUkJ9PrIxQPRD9ldXnz490rs+eJceP7atBQlsgxqqBRSWBxeWByh+Y9Di03oUDQgNLVYUBTx/qdn0WR1oyAnBTdeMxheXzA0u4bVjWZrK2qbnbA6vB0u/pNKhHCBnKFXoTC3rWjWKpCiUSBFE5puS6eWh2dsEEURIgCFTAKlXNrrF4KplTIMblsYgoiIiPqviIX3ypUroVQqsXPnTuTn54e3V1VV4bnnnsPKlSvxwgsvxDVI6j/8gSBOVLTAHxCRlhJaTSo0l2poX/tMGPuP1WH351XwegO4amQ2xhZloMnSGupHtrSi2eZBWooSA7N1SEtRQq1R4OszTTh8sgH/948aAMCgnBQsmTUM44oyuiyGRVGEy+OHw+WDVi2HRiWL2+IBRERERN2JWHgfOHAABw8ehFqt7rA9Pz8fTz31FKZMmRK34Kj/qGtx4eOvanDwWC1sP1gwpH11vh+uPjdhuBELpw7GAGPnFyB8X/tFG+3TqzndfhTl6iOOPguCAK2q/069RkRERIkjYuGdlpaGEydOYPz48eftO3nyJAwGQ1wCo0tPIBiExxu6wLDe3IqaZidqm5yobHCgvMYGiSBg3JAMTBuXC4NOGVogxdG2SIoohi4qlIe+Bpv0yMuKXHD/kEQQYMrQxuHREREREcVXxML75z//OZYuXYrp06djxIgR4R7v0tJS7N27F0899VRvxEl9wOby4qMvzuHAsVrYXT54/cHzbqNVyWDK0OKfri3ElDEmGHTK8L5BOSm9GS4RERHRJS1i4T1//nyMGDECO3bswJdffgmXywWNRoOhQ4fizTffxJAhQ3ojTupFDWYX/vr3Kuw/VgufP4ixRRkwZWigVoSmwlMpZTAa1MjN0ECv7X7hEiIiIiIKiWo6waFDh+LnP/95vGOhPiCKIurNrThzzooz1VaUVVtR0+SEVCpg8ugczLlqIFs7iIiIiGIgqsK7rKwM27dvx+nTp8PzeA8dOhQLFy5EUVFRvGOkOGj1+PHZiXr835FqVLateKhRylA0IBUTR2ZjyhgT0lKUEe6FiIiIiKIVsfDesWMHVq1ahenTp+PKK6/s0ON966234qmnnsINN9zQG7FSDNS1uLDr75X49EQ9PN4A8rN0uG3WMIwYlAZThoZT7RERERHFScTCe/369Xj55Zc7ndXkiy++wOOPP87Cux+wOr1478C3+L8jNZBJBVxVnI1rL89FoSnylHxERERE1HMRC2+z2YxRo0Z1um/kyJEwm80xD4pix+MN4K+HK7HzUCV8viCuvTwXC6YMjri8OBERERHFVsTCe/LkyVi5ciWWL1+OgQMHhrdXVlZiw4YNmDx5clwDpIvjcvvx0ZfnsOtwFRytPowfZsSiawt5oSQRERFRH4lYeK9Zsybcxy2Xy6HVauF0OuH3+zF79mysWbOmN+KkKLncPuw6XIW/fX4OLo8fY4syMH9yAYoGpPZ1aERERERJLWLhnZqaivXr16O1tRUVFRXhWU0KCgrOW0ae+ta5Bgee23oUTVY3rhhmxPzJBVzEhoiIiOgSEdV0ggCgVqtRXFwcz1ioB45804hXdpyASiHFv90xniPcRERERJcYSU9+2ev1YsaMGbGKhS6CKIrYcbACz287htwMDZ6860oW3URERESXoB4V3gBQXV0d1e2+/fZb3HLLLZgzZw5uueUWVFRUdHnb8vJyjBs3DuvWrQtva21txfLlyzFr1izMnTsXe/fu7Wno/Z7L7cNL27/Gto/LMWlkNn655AouekNERER0iYrYatJde4koilHPAV1SUoIlS5Zg4cKF2L59O5588kls2bLlvNsFAgGUlJRg5syZHbb//ve/h06nw+7du1FRUYHbbrsNu3btglabnLN0nDlnxcvvfQ2z3YPFPyrC3IkDOR83ERER0SUsqosr16xZgyFDhpy3z+v1Yv78+REP0tzcjBMnTuDVV18FAMybNw+rV69GS0sL0tPTO9z2lVdewY9+9CO4XC64XK7w9p07d+I3v/kNAKCgoACjR4/Gxx9/jOuvvz7i8RNJMCji/U8rsH1/BdL1SvzqjitQlMvWEiIiIqJLXcTCe9SoUTCbzR3m8G7n9XohimLEg9TW1iI7OxtSqRQAIJVKkZWVhdra2g6Fd2lpKfbv348tW7bgxRdf7HAfNTU1GDBgQPhnk8mEurq6iMf+vowM3QXdPpaMxtjMLvKbLYdx4KsaXHt5Hu6/eSw0KnlM7rc/iFUOkx3zGBvMY88xh7HBPMYG89hzzGFkEQvvFStWQCbr/GYKhQJ79uyJSSA+nw9PPPEE1q5dGy7QY6252YFgMPIbhVgzGlPQ2Gjv8f18U2XBga9qsGBKARZOHQyn3Q2n3R2DCC99scphsmMeY4N57DnmMDaYx9hgHnuOOfyORCJ0OdgbsfAeOnRot/u/PwrdFZPJhPr6egQCAUilUgQCATQ0NMBkMoVv09jYiMrKStx3330AAJvNBlEU4XA4sHr1auTm5qK6ujo8Ql5bW4uJEydGPHYiefeTcqRqFbh+0iD2cxMRERH1M1HP4x0MBvHJJ5+gvLwc2dnZmDZtGnS66Fo3MjIyUFxcjB07dmDhwoXYsWMHiouLO7SZ5Obm4tChQ+Gfn3/+ebhcLvzyl78EAMydOxdvvfUWxowZg4qKChw7dgz/+Z//GW34/d7JihaUVlqwZOZQKOXx+USAiIiIiOInqukES0tLsXDhQuzZswcKhQInT57EkiVLUFVVFfWBVq1ahddeew1z5szBa6+9hqeeegoAsHTpUhw7dizi799zzz2w2WyYNWsWfvazn+Hpp5+OuvDv70RRxP/b/y3SUpS49rLcvg6HiIiIiC6CIEa4OrKlpQW33norNmzY0GFqwU8//RRvvfUW1q9fj82bN2Pp0qWQSHo8LXhc9dce7+PlzVj/l69wx5zhuO7yyK09iYi9Y7HBPMYG89hzzGFsMI+xwTz2HHP4nR71eG/evBm33XYbiouLcc8998Dn84X3VVVVQSKR4MyZM3j99ddx++23xy5qAtA22v3Jt8jQK3HNWFPkXyAiIiKiS1LEIep9+/Zh3rx5AIApU6bgiiuuQElJCa644gosXrwYQKhdZNu2bfGNNEl9VdaMb2ttmD9lMGTSS/sTBSIiIiLqWsRKrrm5GRkZGQCAV199FQ8//DCKiorw0EMPYevWrQBCM59cSL83RScoinj3k3IYDSpMHp3T1+EQERERUQ9ELLzT0tLCC9Wkpqbi4MGDAICDBw9CpVIBAMxmM1JSOGl6rB08VofKegduuqaQo91ERERE/VzEHu9p06bhvffew3333YcnnngCjz32GILBIKRSKf7jP/4DALB7925Mnjw57sEmE7fXj60fl6EoV4+JI7P7OhwiIiIi6qGIhfe9996Lf/7nf8Z1112HiRMn4pNPPkFLS0t4Du6ysjK8/PLL2LJlS9yDTSYffFYJq8OLB28aw8VyiIiIiBJAxP6F7OxsPPvss1i2bBleeeUVVFdXQ6/Xo7a2Fq+++ip+9rOfYe3atcjLy+uNeJNCs9WNv/69EpNGZqNoQGpfh0NEREREMRDVypXjx4/H1q1b8dprr+Hxxx9Hc3Mz0tPTMWnSJLz11lvhiy8pNt75vzIIAG7+UVFfh0JEREREMRL1kvEGgwEPPvggHnzwwXjGk/TOnLPi0Il6LJhSgHS9qq/DISIiIqIYiVh4e71e1NXVYeDAgQCA9957D8FgMLx/7ty54dlNqOfe+ug0DDoFrp84qK9DISIiIqIYilh4b9myBXV1dfj3f/93AMCTTz6JkSNHAgjN8W02m3H33XfHN8ok0WhpRVmNDbdOHwKlQtrX4RARERFRDEUsvN9//33813/9V/hnuVyO119/HQBQUVGBX/ziFyy8Y6T0rBkAMKqQPfNEREREiSbirCa1tbUoKCgI/3zNNdeEvy8oKEBNTU1cAktGJyvN0GsVyM3Q9HUoRERERBRjEQtvr9cLm80W/nn9+vXh7202G7xeb3wiSzKiKOLkWTOKB6Vx3m4iIiKiBBSx8B49ejR27drV6b6//vWvGDVqVMyDSkZ1LS5YHV4UD0rr61CIiIiIKA4i9nj/7Gc/wyOPPAKHw4HZs2cjMzMTjY2N2L17N1544QX87ne/6404E157f/eIgYY+joSIiIiI4iFi4T1lyhSsXr0a69atw7p168Lbs7Oz8fTTT2Pq1KlxDTBZnDxrRoZeCaNB3dehEBEREVEcRLWAzvXXX4/rr78e5eXlMJvNMBgMKCwsZC9yjARFEaWVFowbksGcEhERESWoiD3eNTU12Lp1KwCgsLAQ48ePR1FREQRBwLZt21BXVxf3IBPduQYHHK0+9ncTERERJbCIhffGjRvh8Xg63ef1erFx48aYB5VsvuvvZuFNRERElKgiFt6fffYZFixY0Om++fPn48CBAzEPKtmcPGtGdroG6XpVX4dCRERERHESsfBuaWmBRtP5gi4qlQpmsznmQSWTQDCIU1UWtpkQERERJbiIhXdWVhZOnjzZ6b7S0lIYjcaYB5VMKurscHsDLLyJiIiIElzEwnvevHl44oknUF9f32F7fX09Vq1a1WUbCkWnvb97OOfvJiIiIkpoEacTXLZsGb7++mvMmTMHY8aMQVZWFhoaGnDs2DFMnjwZy5Yt6404E1bpWTPyjFroNYq+DoWIiIiI4ihi4S2Xy7Fp0yYcPHgQn376KSwWCy677DLcf//9uPrqq3sjxoTlDwRx+pwV0y7L7etQiIiIiCjOolpABwAmT56MyZMnxzOWpNNi98DrD2JgVkpfh0JEREREcRZV4X3mzBk8//zz+OKLL2CxWGAwGDB+/Hg8+OCDGDp0aLxjTFgWe2h+9LQUZR9HQkRERETxFvHiyoqKCvzkJz+Bx+PBz3/+c7z00ktYvnw53G43brnlFpSXl/dGnAnJ4ggV3gYd+7uJiIiIEl3EEe+XX34ZCxcuRElJSQnVJa4AABn8SURBVIftN998M1avXo3Nmzdj7dq1cQswkbWPeBs44k1ERESU8CKOeB8+fBg//elPO913991349ChQzEPKllYHF4oZBJolFG32hMRERFRPxXVypV5eXmd7svNzeXKlT1gdnhg0CkhCEJfh0JEREREcRax8AbQZWEokUhYNPaAxe5hfzcRERFRkojY4+B2u3Hbbbd1uk8URXg8npgHlSzMDg8KcjiVIBEREVEyiFh4//rXv+52/+LFi2MWTDIRRREWhwcGXWZfh0JEREREvSBi4X3TTTfF5EDffvstVqxYEZ4HfN26dSgoKOhwm61bt+KPf/wjJBIJgsEgFi9ejDvvvBMA8Pzzz+P1119HVlYWAOCKK644b6aV/qTVE4DXF4RBxxlNiIiIiJJBxML73XffjXgnN954Y8TblJSUYMmSJVi4cCG2b9+OJ598Elu2bOlwmzlz5mDRokUQBAEOhwPz58/HVVddhREjRoSP88tf/jLisfoDs4OL5xARERElk4iF91/+8pdOtwuCgLKyMlit1oiFd3NzM06cOIFXX30VADBv3jysXr0aLS0tSE9PD99Op9OFv3e73fD5fAl78SYXzyEiIiJKLhEL79dff/28baWlpdiwYQMA4NFHH414kNraWmRnZ0MqlQIApFIpsrKyUFtb26HwBoA9e/Zg/fr1qKysxKOPPorhw4eH973//vvYv38/jEYjHnroIVx++eURj/19GRm6yDeKE6Ox40WUwbOhaRgLB6XDmNl3cfUnP8whXRzmMTaYx55jDmODeYwN5rHnmMPILmjlloqKCjz33HPYv38/7rzzTjz77LMdRqljYcaMGZgxYwZqamrwwAMPYNq0aSgsLMStt96KZcuWQS6X48CBA7j//vvxwQcfIC0tLer7bm52IBgUYxpvNIzGFDQ22jtsq6yxAgCCXv95++h8neWQLhzzGBvMY88xh7HBPMYG89hzzOF3JBKhy8HeqObxrqmpwa9+9Sv80z/9E0wmE3bt2oUHH3ww6qLbZDKhvr4egUAAABAIBNDQ0ACTydTl7+Tm5mLMmDHYt28fAMBoNEIulwMApkyZApPJhNOnT0d1/EuRxe6FRimDUi7t61CIiIiIqBdELLyffvppzJ8/H1qtFrt27cLjjz8Og8FwQQfJyMhAcXExduzYAQDYsWMHiouLz2szKSsrC3/f0tKCQ4cOYdiwYQCA+vr68L6TJ0+iuroagwcPvqA4LiUWhwcGXlhJRERElDSi6vFWq9XYvXs3/va3v3V6m/ZR6e6sWrUKK1aswIsvvgi9Xo9169YBAJYuXYqHH34YY8aMwVtvvYUDBw5AJpNBFEXcfvvtmDp1KgBg/fr1+PrrryGRSCCXy/Hb3/4WRqPxAh7qpcXs8CCNF1YSERERJY2IhfcPp/y7WEVFRXj77bfP27558+bw9ytXruzy99sL9URhcXhgGhh9fzoRERER9W8RC++rrrqqN+JIKkFRhNXhZasJERERURKJ6uJKii27y4dAUOSqlURERERJhIV3H7DY2xfPYeFNRERElCxYePcBLhdPRERElHxYePcBLhdPRERElHyiXrnSYrHgD3/4A06ePAmXy9Vh35///OeYB5bILHYPBAB6LQtvIiIiomQRdeH96KOPwuv14vrrr4darY5nTAnP4vBAr1VAJuUHDkRERETJIurC+8iRI/jss8+gUHCUtqcsDi8vrCQiIiJKMlEPuQ4fPhx1dXXxjCVpWOwe9ncTERERJZmoR7wnTZqEe++9F4sWLUJmZmaHfTfffHPMA0tkZocHhbn6vg6DiIiIiHpR1IX3559/juzsbBw4cKDDdkEQWHhfAH8gCLvLx1YTIiIioiQTdeH9pz/9KZ5xJI3wVIKcw5uIiIgoqURdeAOA1WrF3r17UV9fj+zsbFx33XVITU2NV2wJyeLwAuCqlURERETJJuqLK48cOYJZs2bhzTffxKlTp/Dmm29i1qxZOHLkSDzjSzjfLRfPiyuJiIiIkknUI95r1qxBSUkJfvzjH4e3ffDBB3jmmWewdevWuASXiLhcPBEREVFyinrEu6KiAtdff32HbXPmzEFlZWXMg0pkFocHUokAnVre16EQERERUS+KuvAeNGgQ3n///Q7bPvzwQ+Tn58c8qERmsYcWzxEEoa9DISIiIqJeFHWrycqVK7Fs2TL86U9/Qm5uLqqrq3H27Fls2rQpnvElHIvDwzYTIiIioiQUdeF9xRVXYPfu3di3bx8aGhpw3XXX4dprr4XBYIhnfAnH4vBgQKa2r8MgIiIiol52QdMJpqamYuHChfGKJSlYHB6MKkjv6zCIiIiIqJd1W3jfc889+P3vfw8AWLJkSZd9yX/+859jH1kCcnv9aPUE2GpCRERElIS6LbxvvPHG8PeLFy+OezCJrn3xnFTO4U1ERESUdLotvOfPnx/+vrCwEOPGjTvvNkePHo19VAnK5mwrvLUc8SYiIiJKNlFPJ3j33Xd3uv3ee++NWTCJzu4KFd4pGs7hTURERJRsIl5cGQwGIYpih692lZWVkEqlcQ0wkdhcPgCAXstWEyIiIqJkE7HwHjlyZPiiypEjR3bYJ5FIsGzZsvhEloDaW024aiURERFR8olYeO/ZsweiKOKOO+7Aa6+9Ft4uCALS09OhUqniGmAisbm80KpkkEmj7vAhIiIiogQRsfAeMGAAAGDv3r1xDybR2Z1etpkQERERJakLWkBnz549OHz4MMxmc4de79/+9rcxDywR2Vw+6DUsvImIiIiSUdQ9Dy+88AJKSkoQDAbx4YcfwmAwYP/+/dDr9fGML6HYXV6kcMSbiIiIKClFXXhv3boVf/jDH7By5UrI5XKsXLkSmzZtwrlz5+IZX0KxOb3QcypBIiIioqQUdeFts9kwbNgwAIBcLofP58PYsWNx+PDhuAWXSPyBIJxuP1tNiIiIiJJU1D3eAwcOxOnTpzF06FAMHToUb7zxBvR6PVJTU+MZX8JwtIbm8GarCREREVFyirrwXr58OSwWCwDg0UcfxWOPPQaXy4WSkpK4BZdI2ufwZqsJERERUXKKuvC+9tprw9+PGzcOu3fvjktAicoWXi6eI95EREREyajbwruqqiqqO8nPz494m2+//RYrVqyAxWKBwWDAunXrUFBQ0OE2W7duxR//+EdIJBIEg0EsXrwYd955JwAgEAjgmWeewSeffAJBEHDfffdh8eLFUcV3KbA7uVw8ERERUTLrtvCeNWsWBEGAKIrhZeMBnPfzyZMnIx6opKQES5YswcKFC7F9+3Y8+eST2LJlS4fbzJkzB4sWLYIgCHA4HJg/fz6uuuoqjBgxAv/7v/+LyspK7Nq1CxaLBTfeeCOuvvpq5OXlXehj7hPtI968uJKIiIgoOXU7q0lpaSlOnjyJ0tJSPPPMM7jhhhuwc+dOHD16FDt37sS8efPw61//OuJBmpubceLECcybNw8AMG/ePJw4cQItLS0dbqfT6cIFvdvths/nC//8wQcfYPHixZBIJEhPT8fMmTPx4YcfXtSD7gs2lxcyqQC1UtrXoRARERFRH4i6x3vDhg3YtWsXVCoVAKCgoABPP/10eJS6O7W1tcjOzoZUGio6pVIpsrKyUFtbi/T09A633bNnD9avX4/Kyko8+uijGD58ePg+cnNzw7czmUyoq6uLNnwAQEaG7oJuH0u+AGDQKZGVxQWHLpbRmNLXISQE5jE2mMeeYw5jg3mMDeax55jDyKIuvIPBIKqrq1FUVBTeVlNTg2AwGNOAZsyYgRkzZqCmpgYPPPAApk2bhsLCwpjcd3OzA8GgGPmGMWY0pqChxQmtSo7GRnuvHz8RGI0pzF0MMI+xwTz2HHMYG8xjbDCPPcccfkciEboc7I268P6Xf/kX3HXXXVi0aBFycnJQV1eHbdu24a677or4uyaTCfX19QgEApBKpQgEAmhoaIDJZOryd3JzczFmzBjs27cPhYWFMJlMqKmpwdixYwGcPwJ+qQstF8+pBImIiIiSVdQrV957771Ys2YNmpqa8NFHH6GxsRFr1qzB0qVLI/5uRkYGiouLsWPHDgDAjh07UFxcfF6bSVlZWfj7lpYWHDp0KLxa5ty5c/H2228jGAyipaUFf/vb3zBnzpxow+9zNqePF1YSERERJbGoR7wBYNq0aZg2bdpFHWjVqlVYsWIFXnzxRej1eqxbtw4AsHTpUjz88MMYM2YM3nrrLRw4cAAymQyiKOL222/H1KlTAQALFy7EV199hdmzZwMAHnjggaimMbwUiKIIu8vLwpuIiIgoiXVbeL/00kv413/9VwChiyu78sgjj0Q8UFFREd5+++3ztm/evDn8/cqVK7v8falUiqeeeiricS5FrR4/vP4gW02IiIiIkli3hff3Zw250BlE6DtWB+fwJiIiIkp23Rbe3x9hXrt2bdyDSVRWhwcAV60kIiIiSma9tmR8MrO0F94c8SYiIiJKWlEvGd8VQRCiWjI+mbWPeKdo2ONNRERElKy6LbxLS0t7K46EZgkX3hzxJiIiIkpWUc/jTRfP6vBCrZRBLmO6iYiIiJJV1PN4+/1+vP766zh8+DDMZnOH9pM///nPcQkuUVjtHujZZkJERESU1KIegl27di3eeustTJgwAV9//TVmz56N5uZmTJo0KZ7xJQSLw4MUzmhCRERElNSiLrx37dqFzZs346677oJUKsVdd92FjRs34tChQ/GMLyFYHB6ksr+biIiIKKlFXXi73W6YTCYAgEqlQmtrK4qKinDixIm4BZcorBzxJiIiIkp6Ufd4FxUV4dixYxg7dixGjx6N559/HjqdDtnZ2fGMr98LBkXYnF72eBMREREluYgj3sFgEACwcuVKSKVSAMCKFStw4sQJ7N27F6tXr45vhP2co9UHUeRUgkRERETJLuKI97Rp07BgwQIsXLgQw4cPBwAUFBTgj3/8Y7xjSwg2lxcAl4snIiIiSnYRR7xXrVqFc+fOYfHixbjpppvwP//zP2hpaemN2BKC3dlWeLPVhIiIiCipRRzxnjlzJmbOnAmbzYYPPvgA27dvx7PPPoupU6fipptuwvTp0yGXs6jsis3lA8BWEyIiIqJkF/WsJnq9HrfeeiveeOMN7Ny5E6NHj8batWsxderUeMbX77HVhIiIiIiAi1gy3uv14tixYzh69CiampowbNiweMSVMOwuLyQSARpV1BPIEBEREVECiroa/Pzzz7F9+3Z8+OGHSE9Px4IFC1BSUoIBAwbEM75+z+b0wqBTQCIIfR0KEREREfWhiIX3888/j/feew8WiwVz587Fpk2bMH78+N6ILSHYnD6k6pR9HQYRERER9bGIhfdXX32F5cuXY+bMmVAqWUBeKLvLy8KbiIiIiCIX3v/93//dG3EkLJvLi/wcfV+HQURERER97IIvrqQLY3Ox1YSIiIiIWHjHlccXgMcbQKqOUwkSERERJTsW3nFkb5vD28ARbyIiIqKkx8I7jhytoVUrU1NYeBMRERElOxbecTQgU4d5kwswdkhmX4dCRERERH2MhXccyWUSLJpWCJWCq1YSERERJTsW3kREREREvYCFNxERERFRL2DhTURERETUC1h4ExERERH1gqS66k8iEZLy2ImCOYwN5jE2mMeeYw5jg3mMDeax55jDkO7yIIiiKPZiLERERERESYmtJkREREREvYCFNxERERFRL2DhTURERETUC1h4ExERERH1AhbeRERERES9gIU3EREREVEvYOFNRERERNQLWHgTEREREfUCFt5ERERERL2AhTcRERERUS9g4R1H3377LW655RbMmTMHt9xyCyoqKvo6pEue2WzG0qVLMWfOHMyfPx8PPvggWlpaAAD/+Mc/sGDBAsyZMwc//elP0dzc3MfRXvpeeOEFDB8+HN988w0A5vBCeTwelJSUYPbs2Zg/fz6eeOIJAHxtX6i9e/fixhtvxMKFC7FgwQLs2rULAPMYybp16zB9+vQOr2Gg+7wxp+frLI/dnWsA/q38oa6ei+1+eK4BmMMuiRQ3d9xxh/juu++KoiiK7777rnjHHXf0cUSXPrPZLH722Wfhn3/zm9+Iv/rVr8RAICDOnDlTPHz4sCiKorhx40ZxxYoVfRVmv3D8+HHxnnvuEa+77jrx1KlTzOFFWL16tfjrX/9aDAaDoiiKYmNjoyiKfG1fiGAwKE6YMEE8deqUKIqiePLkSfGyyy4TA4EA8xjB4cOHxZqamvBruF13eWNOz9dZHrs614iiyL+VnejquSiK559rRJE57A5HvOOkubkZJ06cwLx58wAA8+bNw4kTJzq8o6bzGQwGTJw4MfzzZZddhpqaGhw/fhxKpRITJkwAANx666348MMP+yrMS57X68XTTz+NVatWhbcxhxfG6XTi3XffxSOPPAJBEAAAmZmZfG1fBIlEArvdDgCw2+3IysqC2WxmHiOYMGECTCZTh23dPf/43OxcZ3ns6lwD8G9lZzrLIdD5uQZgDrsj6+sAElVtbS2ys7MhlUoBAFKpFFlZWaitrUV6enofR9c/BINBvPHGG5g+fTpqa2uRm5sb3peeno5gMAiLxQKDwdCHUV6aNmzYgAULFiAvLy+8jTm8MFVVVTAYDHjhhRdw6NAhaLVaPPLII1CpVHxtXwBBEPC73/0O999/PzQaDZxOJ1555RX+jbxI3eVNFEXm9CJ8/1wD8G/lhejsXAMwh93hiDddslavXg2NRoPbb7+9r0PpV44cOYLjx49jyZIlfR1KvxYIBFBVVYWRI0di27ZteOyxx/DQQw/B5XL1dWj9it/vx8svv4wXX3wRe/fuxUsvvYTly5czj3TJ4Lnm4vBcc3E44h0nJpMJ9fX1CAQCkEqlCAQCaGho6PSjGjrfunXrcPbsWWzatAkSiQQmkyn8MSAAtLS0QCKRJP07584cPnwYZWVlmDFjBgCgrq4O99xzD+644w7m8AKYTCbIZLLwx/bjxo1DWloaVCoVX9sX4OTJk2hoaMD48eMBAOPHj4darYZSqWQeL0J35xZRFJnTC/TDcw0Anm+i1NW5Zu3atcxhNzjiHScZGRkoLi7Gjh07AAA7duxAcXExP+6Lwvr163H8+HFs3LgRCoUCADB69Gi43W58/vnnAIA333wTc+fO7cswL1n33Xcf9u/fj48++ggfffQRcnJy8Pvf/x733nsvc3gB0tPTMXHiRBw4cABAaLaI5uZmFBQU8LV9AXJyclBXV4fy8nIAQFlZGZqbmzFo0CDm8SJ0d27heefCdHauAXi+iVZX55qpU6cyh90QRFEU+zqIRFVWVoYVK1bAZrNBr9dj3bp1KCws7OuwLmmnT5/GvHnzUFBQAJVKBQDIy8vDxo0b8eWXX6KkpAQejwcDBgzAs88+i8zMzD6O+NI3ffp0bNq0CcOGDWMOL1BVVRVWrlwJi8UCmUyG5cuX49prr+Vr+wK999572Lx5c/gi1YcffhgzZ85kHiN45plnsGvXLjQ1NSEtLQ0GgwHvv/9+t3ljTs/XWR5/97vfdXmuAcC/lT/Q1XPx+75/rgGYw66w8CYiIiIi6gVsNSEiIiIi6gUsvImIiIiIegELbyIiIiKiXsDCm4iIiIioF7DwJiIiIiLqBSy8iYjoog0fPhxnz57t6zCIiPoFrlxJRJRApk+fjqamJkil0vC2m266CU8++WQfRkVERAALbyKihLNp0yZMnjy5r8MgIqIfYKsJEVES2LZtG2699VY8/fTTGD9+PObOnYtPP/00vL++vh7Lli3DVVddhVmzZuEvf/lLeF8gEMCmTZswc+ZMXH755Vi0aBFqa2vD+w8ePIjZs2djwoQJeOqpp9C+LtvZs2dx++23Y/z48Zg4cSKWL1/eew+YiOgSxBFvIqIkcfToUcydOxefffYZdu/ejQcffBB79uyBwWDAL37xCwwdOhSffPIJysvLcffddyM/Px9XX301Xn31Vbz//vt45ZVXMHjwYJw6dSq8zDYA7Nu3D++88w4cDgcWLVqE6667DtOmTcOGDRswZcoUbNmyBT6fD8eOHevDR09E1Pc44k1ElGAeeOABTJgwIfzVPnqdnp6Ou+66C3K5HDfccAMGDx6Mffv2oba2Fl9++SUee+wxKJVKFBcXY/Hixdi+fTsA4O2338YjjzyCwsJCCIKAESNGIC0tLXy8pUuXQq/XIzc3FxMnTkRpaSkAQCaToaamBg0NDVAqlZgwYULvJ4OI6BLCwpuIKMFs3LgRn3/+efjrJz/5CQAgOzsbgiCEb5ebm4uGhgY0NDQgNTUVOp2uw776+noAQF1dHQYOHNjl8YxGY/h7tVoNp9MJAHj88cchiiJuvvlm/PjHP8Y777wT08dJRNTfsNWEiChJ1NfXQxTFcPFdW1uL6dOnIysrC1arFQ6HI1x819bWIjs7GwCQk5ODyspKDBs27IKOZzQa8cwzzwAAPv/8c9x999248sorMWjQoBg+KiKi/oMj3kRESaKlpSXcb71z506UlZXh2muvhclkwuWXX47169fD4/GgtLQU77zzDhYsWAAAWLx4MTZs2ICKigqIoojS0lKYzeaIx9u5cyfq6uoAAKmpqRAEARIJTztElLw44k1ElGCWLVvWYR7vyZMnY8aMGRg7dizOnj2LSZMmITMzE88991y4V3v9+vUoKSnBNddcA71ej4ceeig8JeHdd98Nr9eLn/70pzCbzSgsLMTGjRsjxnHs2DGsWbMGDocDGRkZ+Ld/+zfk5+fH50ETEfUDgtg+7xMRESWsbdu24e2338Ybb7zR16EQESUtfuZHRERERNQLWHgTEREREfUCtpoQEREREfUCjngTEREREfUCFt5ERERERL2AhTcRERERUS9g4U1ERERE1AtYeBMRERER9YL/Dzhuvnp+WH/0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMdqcRMWKbIf"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wOALoUOKbIf"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bJdNtXpKbIf"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z14AeVaKbIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc928055-86cc-4078-bbbc-48d40f74b2ea"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Scale of 0 disables regularizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IfeVohUKbIf"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axVRJgY-KbIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99e8ce2-577a-40ed-907c-30acb41f0088"
      },
      "source": [
        "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-25m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/drive/My Drive/Study/Project3/ml-25m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3wWxPvKbIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e14f146-7584-46fc-deaf-b717c1b78875"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Study/Project3/ml-25m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQW1bzwkKbIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3fd460-c469-4f74-dc01-e0721be8a79c"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.43359 (0.00162)\n",
            "Test Recall@20=0.39622 (0.00204)\n",
            "Test Recall@50=0.53407 (0.00216)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}