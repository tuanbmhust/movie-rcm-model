{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vae_10m.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhQ8g-UDLpqn",
        "outputId": "fde57c1e-1258-428d-d1b1-442186ed8eb1"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y-MU2H5KbIZ"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBvM4FolKbIZ"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqHVSXvVKbIa"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "import bottleneck as bn\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jSKlwM2KbIa"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FfmcWszKbIa"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6aQkgc3KbIa",
        "outputId": "7ba815f0-0e5b-4614-efc9-1ba5e537e87d"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/drive/My Drive/Study/Project3/ml-10m'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBQWbvSKbIa"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7xOWy9KbIa"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "C_YwUsZwKbIa",
        "outputId": "097a9eb1-9acb-42b8-d7da-542756b58ca4"
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>122</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838985046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>185</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>231</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>292</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>316</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1      122     5.0  838985046\n",
              "1       1      185     5.0  838983525\n",
              "2       1      231     5.0  838983392\n",
              "3       1      292     5.0  838983421\n",
              "4       1      316     5.0  838983392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75JhuEB_KbIb"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdOzp4RfKbIb"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChLy_ymAKbIb"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlcITsDZKbIb"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RYQPeH2KbIb"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQGWw184KbIb"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9-rt2ezKbIb",
        "outputId": "a00fd3f0-9dec-49aa-8038-464792e97d82"
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 5003786 watching events from 69167 users and 10258 movies (sparsity: 0.705%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbyWcf1pKbIb"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTku1H1DKbIb"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdASvG79KbIb"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0HiGtOKbIb"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Av46YOzKbIc"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8MYrWjdKbIc"
      },
      "source": [
        "# pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW7cBfvNKbIc"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLuS5LXwKbIc"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pCxg4OUKbIc",
        "outputId": "e24efd3a-df69-4f20-a9f2-b63df027d9f0"
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpz_DX0KbIc"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q_LYlJFKbIc",
        "outputId": "41163c55-3017-46f4-801c-1574644c8f08"
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D12r0whSKbIc"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F_kXEokKbIc"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
        "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUHPsKhZKbIc"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRNSTf0QKbIc"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4o0GVKaKbIc"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KBW_3aqKbIc"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdB3PRQJKbIc"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZLq8QkKbIc"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIlMAfz4KbId"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCPIIYYMKbId"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEcLKHvcKbId"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvW4hHdrKbId"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dIsvORCKbId"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2LESs4KbId"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P1xXakVKbId"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iVFyI_KbId"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxhsnuTDKbId"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHeuM78SKbId"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzi4hI4uKbId"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nrgFBSQKbId"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVN2K0N5KbId"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1zbIgdXKbId"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWW9jkv8KbId"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2uu1M_KbId"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epbUOpjQKbId"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = list(range(N))\n",
        "\n",
        "# training batch size\n",
        "batch_size = 500\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = list(range(N_vad))\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe8WpfC4KbId"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpg3DDfBKbId"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvMW1xduKbId"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklHu46iKbId"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIxPZcRwKbId"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txnn1fc1KbId"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zguWFBo8KbIe"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJkeTnt4KbIe",
        "outputId": "400b385b-bad6-4033-ab4c-55dbccaaaa0e"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-29-238c8eded668>:40: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5U-tOm1KbIe"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYqzMPB0KbIe"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_6LvF7JKbIe",
        "outputId": "f3d9824d-c7d8-463d-d66b-2d905505c92d"
      },
      "source": [
        "log_dir = '/content/drive/My Drive/Study/Project3/ml-10m/log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/drive/My Drive/Study/Project3/ml-10m/log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtRExyrSKbIe",
        "outputId": "e56b01e3-cf2d-4e04-8652-afbc4f99023f"
      },
      "source": [
        "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-10m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/drive/My Drive/Study/Project3/ml-10m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSJJOgKJKbIf"
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGnvfwA-KbIf"
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YxiD4pwKbIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "3d0d0ad4-ca99-4c0d-c8c7-2cf37b7b33a0"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMdqcRMWKbIf"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wOALoUOKbIf"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bJdNtXpKbIf"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z14AeVaKbIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24c82ad-dd5c-4f12-eb92-5c3df43ee353"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Scale of 0 disables regularizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IfeVohUKbIf"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axVRJgY-KbIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d64e1a3-d189-47be-f3d0-9074538e533f"
      },
      "source": [
        "chkpt_dir = '/content/drive/My Drive/Study/Project3/ml-10m/checkpoints/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/drive/My Drive/Study/Project3/ml-10m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3wWxPvKbIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0355074b-cda6-4eba-dea6-570bf3e791b8"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Study/Project3/ml-10m/checkpoints/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQW1bzwkKbIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf023c16-f639-4a53-b225-7a8553f49106"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.43345 (0.00209)\n",
            "Test Recall@20=0.40789 (0.00273)\n",
            "Test Recall@50=0.55314 (0.00290)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}